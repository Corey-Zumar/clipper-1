{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clipper Tutorial : R model deployment using RPy2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial will walk you through the process of starting Clipper, deploying R models to Clipper and creating & querying a Clipper application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting Clipper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, Docker and Docker-Compose must be installed before deploying Clipper\n",
    "Make sure your Docker daemon, local or remote, is up and running.\n",
    "\n",
    "If you'd like to deploy Clipper locally, you can leave the user and key variables blank and set host=\"localhost\". Otherwise, you can deploy Clipper remotely to a machine that you have SSH access to. Set the user variable to your SSH username, the key variable to the path to your SSH key, and the host variable to the remote hostname or IP address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if Docker is running...\n",
      "Clipper is running\n"
     ]
    }
   ],
   "source": [
    "# clipper_manager must be on your path:\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../../clipper_admin/'))\n",
    "import clipper_manager as cm\n",
    "# Change the username if necessary\n",
    "user = \"\"\n",
    "# Set the path to the SSH key\n",
    "key = \"\"\n",
    "# Set the SSH host\n",
    "host = \"localhost\"\n",
    "clipper = cm.Clipper(host, user, key)\n",
    "\n",
    "clipper.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You now have a running Clipper instance that you can start to interact with.\n",
    "Now we shall look to forge an R model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developing an R model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import R_model_support as RS\n",
    "\n",
    "RS.ro.r('data(mtcars)')\n",
    "model_cars =RS.ro.r('model_R <- lm(mpg~wt,data=mtcars)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable 'model_cars' is linear regression model and the dataset used to train it is \"mtcars\" provided by R itself. We now have to deploy model_cars in an R model container."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying R model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before deploying R model , make sure u have an image for R-Python container. To build the image, run the shell command: \"cd (clipper-root)/containers/R-Python/ && docker build -t clipper/r_python_container .\"\n",
    "\n",
    "\n",
    "Now run the following :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Published model to Clipper\n",
      "Found clipper/r_python_container:latest on host\n",
      "Copied model data to host\n",
      "Model deploy successful? True\n"
     ]
    }
   ],
   "source": [
    "model_name = \"the_R_model\"\n",
    "\n",
    "\n",
    "model_added = clipper.deploy_R_model(\n",
    "    model_name,\n",
    "    1,\n",
    "    model_cars,\n",
    "    \"clipper/r_python_container:latest\",\n",
    "    [\"time-series\", \"R\"],\n",
    "    \"strings\",\n",
    "    num_containers=1\n",
    ")\n",
    "print(\"Model deploy successful? {success}\".format(success=model_added))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to create an application to carry out predictions with the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registering Application "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "app_name = \"R_app\"\n",
    "app_model=model_name\n",
    "default_output = \"0\"\n",
    "\n",
    "clipper.register_application(\n",
    "    app_name,\n",
    "    app_model,\n",
    "    \"strings\",\n",
    "    default_output,\n",
    "    slo_micros=200000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that 'R_app' is created, let us use it to carry out predictions.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Serving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you should create a 'pandas DataFrame' that will be converted to R dataframe before passing it to model's predict function. The pandas DataFrame should be created in accordance with the deployed R model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response : 0\n",
      "'{\"query_id\":0,\"output\":8.26464552746,\"default\":false}', latency is : 16.524000 ms\n",
      "\n",
      "\n",
      "response : 1\n",
      "'{\"query_id\":1,\"output\":5.21829673101,\"default\":false}', latency is : 12.308000 ms\n",
      "\n",
      "\n",
      "response : 2\n",
      "'{\"query_id\":2,\"output\":-4.88275454144,\"default\":false}', latency is : 12.910000 ms\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=RS.DataFrame({'wt':[5.43,6.00,7.89],'ht' :[4.32,5.76,7.90]})\n",
    "RS.start_prediction(df,app_name,host)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also convert R data frames to pandas DataFrames and carry out predictions with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response : 0\n",
      "'{\"query_id\":3,\"output\":23.2826106468,\"default\":false}', latency is : 23.099000 ms\n",
      "\n",
      "\n",
      "response : 1\n",
      "'{\"query_id\":4,\"output\":21.9197703958,\"default\":false}', latency is : 23.953000 ms\n",
      "\n",
      "\n",
      "response : 2\n",
      "'{\"query_id\":5,\"output\":24.8859521186,\"default\":false}', latency is : 22.078000 ms\n",
      "\n",
      "\n",
      "response : 3\n",
      "'{\"query_id\":6,\"output\":20.102650061,\"default\":false}', latency is : 16.763000 ms\n",
      "\n",
      "\n",
      "response : 4\n",
      "'{\"query_id\":7,\"output\":18.9001439572,\"default\":false}', latency is : 15.925000 ms\n",
      "\n",
      "\n",
      "response : 5\n",
      "'{\"query_id\":8,\"output\":18.7932545257,\"default\":false}', latency is : 17.179000 ms\n",
      "\n",
      "\n",
      "response : 6\n",
      "'{\"query_id\":9,\"output\":18.2053626527,\"default\":false}', latency is : 14.928000 ms\n",
      "\n",
      "\n",
      "response : 7\n",
      "'{\"query_id\":10,\"output\":20.2362618504,\"default\":false}', latency is : 16.002000 ms\n",
      "\n",
      "\n",
      "response : 8\n",
      "'{\"query_id\":11,\"output\":20.4500407133,\"default\":false}', latency is : 21.080000 ms\n",
      "\n",
      "\n",
      "response : 9\n",
      "'{\"query_id\":12,\"output\":18.9001439572,\"default\":false}', latency is : 19.770000 ms\n",
      "\n",
      "\n",
      "response : 10\n",
      "'{\"query_id\":13,\"output\":18.9001439572,\"default\":false}', latency is : 18.139000 ms\n",
      "\n",
      "\n",
      "response : 11\n",
      "'{\"query_id\":14,\"output\":15.5331268664,\"default\":false}', latency is : 58.286000 ms\n",
      "\n",
      "\n",
      "response : 12\n",
      "'{\"query_id\":15,\"output\":17.3502472011,\"default\":false}', latency is : 33.576000 ms\n",
      "\n",
      "\n",
      "response : 13\n",
      "'{\"query_id\":16,\"output\":17.0830236225,\"default\":false}', latency is : 19.734000 ms\n",
      "\n",
      "\n",
      "response : 14\n",
      "'{\"query_id\":17,\"output\":9.22665041055,\"default\":false}', latency is : 26.170000 ms\n",
      "\n",
      "\n",
      "response : 15\n",
      "'{\"query_id\":18,\"output\":8.29671235689,\"default\":false}', latency is : 21.597000 ms\n",
      "\n",
      "\n",
      "response : 16\n",
      "'{\"query_id\":19,\"output\":8.71892561114,\"default\":false}', latency is : 17.947000 ms\n",
      "\n",
      "\n",
      "response : 17\n",
      "'{\"query_id\":20,\"output\":25.5272887074,\"default\":false}', latency is : 18.404000 ms\n",
      "\n",
      "\n",
      "response : 18\n",
      "'{\"query_id\":21,\"output\":28.6538045774,\"default\":false}', latency is : 14.955000 ms\n",
      "\n",
      "\n",
      "response : 19\n",
      "'{\"query_id\":22,\"output\":27.4780208314,\"default\":false}', latency is : 18.580000 ms\n",
      "\n",
      "\n",
      "response : 20\n",
      "'{\"query_id\":23,\"output\":24.1110037406,\"default\":false}', latency is : 44.946000 ms\n",
      "\n",
      "\n",
      "response : 21\n",
      "'{\"query_id\":24,\"output\":18.4725862314,\"default\":false}', latency is : 18.632000 ms\n",
      "\n",
      "\n",
      "response : 22\n",
      "'{\"query_id\":25,\"output\":18.926866315,\"default\":false}', latency is : 19.087000 ms\n",
      "\n",
      "\n",
      "response : 23\n",
      "'{\"query_id\":26,\"output\":16.7623553281,\"default\":false}', latency is : 18.724000 ms\n",
      "\n",
      "\n",
      "response : 24\n",
      "'{\"query_id\":27,\"output\":16.7356329702,\"default\":false}', latency is : 19.506000 ms\n",
      "\n",
      "\n",
      "response : 25\n",
      "'{\"query_id\":28,\"output\":26.9435736741,\"default\":false}', latency is : 17.796000 ms\n",
      "\n",
      "\n",
      "response : 26\n",
      "'{\"query_id\":29,\"output\":25.8479570017,\"default\":false}', latency is : 85.004000 ms\n",
      "\n",
      "\n",
      "response : 27\n",
      "'{\"query_id\":30,\"output\":29.1989406778,\"default\":false}', latency is : 18.983000 ms\n",
      "\n",
      "\n",
      "response : 28\n",
      "'{\"query_id\":31,\"output\":20.3431512818,\"default\":false}', latency is : 33.622000 ms\n",
      "\n",
      "\n",
      "response : 29\n",
      "'{\"query_id\":32,\"output\":22.4809399109,\"default\":false}', latency is : 37.628000 ms\n",
      "\n",
      "\n",
      "response : 30\n",
      "'{\"query_id\":33,\"output\":18.2053626527,\"default\":false}', latency is : 15.946000 ms\n",
      "\n",
      "\n",
      "response : 31\n",
      "'{\"query_id\":34,\"output\":22.4274951952,\"default\":false}', latency is : 15.901000 ms\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = RS.com.load_data('mtcars')\n",
    "RS.start_prediction(df,app_name,host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
